---
layout: post
author: Mattia Racca
title: A writing experiment
date: 2025-09-09 21:00:00
description: Blog posts? in this LLM economy?!
tags: writing research hobbies
categories:
---
This is an experiment: I want to do some writing that is not strictly academic (conference papers, reviews, quarterly reports) for several reasons, personal and professional.
Chiefly, I worry about the increasingly available shortcuts provided by LLMs for writing tasks.

Look, people that know me are well aware that I'm not a fan of ChatGPT and the like.
As much as disliking [a big pile of linear algebra](https://xkcd.com/1838/) that is incredibly good at predicting next tokens is nonsensical (and funny), there is no shortage of things around LLMs that I can take issue with: the energy footprint of the latest models, the indiscriminate stealing of art for training, the perpetuation of racial biases harvested from the internet, or the whole snake oil marketing operation.

Yet, if I zoom-in and take an egoistic view at the problem for a moment, my main issue is about **how easy is to use such tools** and, consequently, **how exposed we are to their shortcomings and dangers.**

<div class="row justify-content-center">
    <div class="col-6">
        {% include figure.liquid loading="eager" path="https://imgs.xkcd.com/comics/machine_learning.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
Mandatory xkcd reference
</div>

People wrote extensively on the topic (*e.g.* the [Stochastic Parrots ðŸ¦œ](https://dl.acm.org/doi/10.1145/3442188.3445922) paper), no need to survey the literature here.
What I find worrying about such tools in my day-to-day life is
- **LLMs make content uniform.** Things may look nice, but they look all so similar. LinkedIn posts (full of em dashes, strategically placed emoji, and cringe comic strips) are the epitome of this flattening process. You can't unsee the [Piss Filter](https://knowyourmeme.com/memes/ai-art-becoming-yellow) of recent GenAI images. Every paper is now [delving into crucial issues](https://arxiv.org/abs/2406.07016). **No thanks, I value originality over presentation.**
- **LLMs make me lazy and complacent.** Why should I write that `bash` script when Copilot can wing it for me in seconds? and why should I then revise/understand it before running it? and, if it sort-of works, why should I try to improve it or clean it? **No thanks, I'm not ready to give up that much agency.**
- **LLMs shift my role from creator to reviewer.** I want to make things, but I end up in a vicious cycle of revising what the LLM produced, begging it to make it right, revising and begging, rinse and repeat. **No thanks, I'm not a ~~LLM-sitter~~ ~~Transformer supplicant~~ prompt engineer.**

In short (and with a PKD quote, of all things), I'm asking myself
> *[...] don't you feel ashamed of yourself when you let a machine tell you what to do?*
> 
> -- [Philip K. Dick, Vulcan's Hammer](https://www.goodreads.com/book/show/22595.Vulcan_s_Hammer)

### So what's with this experiment?
I'm gonna write some blog posts about things I'm interested in, without any GenAI assistance (except for a good ol' dictionary-based spell checker, because I'm not a native speaker of English).
*Maybe*, this will make me feel more creative, more focused (and less prone to unproductive multitasking), and help me regain some agency at my own pace.
